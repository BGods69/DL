{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2cb5989-16db-4174-b5c8-a50ff459c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], d_loss: 0.6261, g_loss: 0.9230\n",
      "Epoch [2/100], d_loss: 0.6429, g_loss: 0.9324\n",
      "Epoch [3/100], d_loss: 0.2378, g_loss: 1.9684\n",
      "Epoch [4/100], d_loss: 1.4385, g_loss: 4.2193\n",
      "Epoch [5/100], d_loss: 3.4767, g_loss: 4.6963\n",
      "Epoch [6/100], d_loss: 1.1495, g_loss: 2.3880\n",
      "Epoch [7/100], d_loss: 0.4785, g_loss: 2.9321\n",
      "Epoch [8/100], d_loss: 0.7469, g_loss: 0.8995\n",
      "Epoch [9/100], d_loss: 1.4935, g_loss: 0.4295\n",
      "Epoch [10/100], d_loss: 1.1057, g_loss: 3.9364\n",
      "Epoch [11/100], d_loss: 1.3725, g_loss: 5.9522\n",
      "Epoch [12/100], d_loss: 1.1523, g_loss: 4.9878\n",
      "Epoch [13/100], d_loss: 0.6431, g_loss: 5.2546\n",
      "Epoch [14/100], d_loss: 1.0472, g_loss: 6.0711\n",
      "Epoch [15/100], d_loss: 0.2665, g_loss: 6.8469\n",
      "Epoch [16/100], d_loss: 0.5779, g_loss: 7.6480\n",
      "Epoch [17/100], d_loss: 0.3265, g_loss: 8.3808\n",
      "Epoch [18/100], d_loss: 0.4605, g_loss: 10.4592\n",
      "Epoch [19/100], d_loss: 0.5311, g_loss: 18.6118\n",
      "Epoch [20/100], d_loss: 0.3360, g_loss: 47.6461\n",
      "Epoch [21/100], d_loss: 0.1350, g_loss: 9.5121\n",
      "Epoch [22/100], d_loss: 0.1407, g_loss: 9.1179\n",
      "Epoch [23/100], d_loss: 0.0691, g_loss: 8.8738\n",
      "Epoch [24/100], d_loss: 0.1370, g_loss: 9.9739\n",
      "Epoch [25/100], d_loss: 0.1182, g_loss: 10.3494\n",
      "Epoch [26/100], d_loss: 0.0634, g_loss: 28.8493\n",
      "Epoch [27/100], d_loss: 0.1245, g_loss: 23.0831\n",
      "Epoch [28/100], d_loss: 0.3312, g_loss: 24.6795\n",
      "Epoch [29/100], d_loss: 0.0675, g_loss: 9.3265\n",
      "Epoch [30/100], d_loss: 0.1532, g_loss: 51.4392\n",
      "Epoch [31/100], d_loss: 0.0442, g_loss: 96.7280\n",
      "Epoch [32/100], d_loss: 0.0150, g_loss: 92.9690\n",
      "Epoch [33/100], d_loss: 0.0129, g_loss: 74.9352\n",
      "Epoch [34/100], d_loss: 0.0100, g_loss: 64.6706\n",
      "Epoch [35/100], d_loss: 0.0097, g_loss: 59.0003\n",
      "Epoch [36/100], d_loss: 0.0026, g_loss: 49.6619\n",
      "Epoch [37/100], d_loss: 0.0243, g_loss: 59.8833\n",
      "Epoch [38/100], d_loss: 0.0426, g_loss: 41.1205\n",
      "Epoch [39/100], d_loss: 0.1830, g_loss: 45.7907\n",
      "Epoch [40/100], d_loss: 0.1323, g_loss: 80.2267\n",
      "Epoch [41/100], d_loss: 0.0854, g_loss: 68.7713\n",
      "Epoch [42/100], d_loss: 0.0671, g_loss: 41.5651\n",
      "Epoch [43/100], d_loss: 0.2173, g_loss: 68.0086\n",
      "Epoch [44/100], d_loss: 0.0593, g_loss: 46.1016\n",
      "Epoch [45/100], d_loss: 0.0729, g_loss: 55.5622\n",
      "Epoch [46/100], d_loss: 0.0490, g_loss: 55.0192\n",
      "Epoch [47/100], d_loss: 0.0321, g_loss: 50.4794\n",
      "Epoch [48/100], d_loss: 0.0191, g_loss: 48.5520\n",
      "Epoch [49/100], d_loss: 0.0080, g_loss: 46.4549\n",
      "Epoch [50/100], d_loss: 0.0014, g_loss: 43.6893\n",
      "Epoch [51/100], d_loss: 0.0005, g_loss: 43.3760\n",
      "Epoch [52/100], d_loss: 0.0015, g_loss: 37.7977\n",
      "Epoch [53/100], d_loss: 0.0013, g_loss: 40.4347\n",
      "Epoch [54/100], d_loss: 0.0195, g_loss: 20.6665\n",
      "Epoch [55/100], d_loss: 0.1826, g_loss: 13.2335\n",
      "Epoch [56/100], d_loss: 0.3095, g_loss: 72.6201\n",
      "Epoch [57/100], d_loss: 0.0262, g_loss: 64.7124\n",
      "Epoch [58/100], d_loss: 0.0993, g_loss: 92.0358\n",
      "Epoch [59/100], d_loss: 0.0483, g_loss: 94.9268\n",
      "Epoch [60/100], d_loss: 0.1053, g_loss: 93.3885\n",
      "Epoch [61/100], d_loss: 0.0472, g_loss: 94.7769\n",
      "Epoch [62/100], d_loss: 0.3575, g_loss: 95.5328\n",
      "Epoch [63/100], d_loss: 0.8109, g_loss: 69.3795\n",
      "Epoch [64/100], d_loss: 0.2429, g_loss: 85.3120\n",
      "Epoch [65/100], d_loss: 0.2531, g_loss: 31.8690\n",
      "Epoch [66/100], d_loss: 0.2081, g_loss: 26.1853\n",
      "Epoch [67/100], d_loss: 0.2805, g_loss: 26.5994\n",
      "Epoch [68/100], d_loss: 0.1261, g_loss: 39.5272\n",
      "Epoch [69/100], d_loss: 0.0489, g_loss: 69.7428\n",
      "Epoch [70/100], d_loss: 0.0249, g_loss: 59.1723\n",
      "Epoch [71/100], d_loss: 0.5357, g_loss: 58.9201\n",
      "Epoch [72/100], d_loss: 0.1031, g_loss: 61.6675\n",
      "Epoch [73/100], d_loss: 0.7065, g_loss: 51.2956\n",
      "Epoch [74/100], d_loss: 0.0538, g_loss: 56.8332\n",
      "Epoch [75/100], d_loss: 0.1259, g_loss: 46.4041\n",
      "Epoch [76/100], d_loss: 0.0918, g_loss: 29.6884\n",
      "Epoch [77/100], d_loss: 0.2082, g_loss: 45.9934\n",
      "Epoch [78/100], d_loss: 0.0842, g_loss: 71.3027\n",
      "Epoch [79/100], d_loss: 0.0255, g_loss: 80.6098\n",
      "Epoch [80/100], d_loss: 0.0062, g_loss: 68.2699\n",
      "Epoch [81/100], d_loss: 0.0030, g_loss: 38.6081\n",
      "Epoch [82/100], d_loss: 0.1205, g_loss: 44.5487\n",
      "Epoch [83/100], d_loss: 0.1857, g_loss: 34.2722\n",
      "Epoch [84/100], d_loss: 0.0517, g_loss: 36.8658\n",
      "Epoch [85/100], d_loss: 0.0254, g_loss: 39.1592\n",
      "Epoch [86/100], d_loss: 0.0264, g_loss: 24.8611\n",
      "Epoch [87/100], d_loss: 0.0209, g_loss: 38.7663\n",
      "Epoch [88/100], d_loss: 0.0939, g_loss: 45.2094\n",
      "Epoch [89/100], d_loss: 0.1316, g_loss: 19.0065\n",
      "Epoch [90/100], d_loss: 0.0363, g_loss: 16.8586\n",
      "Epoch [91/100], d_loss: 0.0983, g_loss: 23.4814\n",
      "Epoch [92/100], d_loss: 0.1836, g_loss: 32.6031\n",
      "Epoch [93/100], d_loss: 0.2239, g_loss: 34.7053\n",
      "Epoch [94/100], d_loss: 0.0828, g_loss: 27.0347\n",
      "Epoch [95/100], d_loss: 0.2153, g_loss: 19.0885\n",
      "Epoch [96/100], d_loss: 0.0327, g_loss: 29.7174\n",
      "Epoch [97/100], d_loss: 0.0900, g_loss: 28.3348\n",
      "Epoch [98/100], d_loss: 0.0403, g_loss: 14.0195\n",
      "Epoch [99/100], d_loss: 0.1856, g_loss: 12.6354\n",
      "Epoch [100/100], d_loss: 0.0206, g_loss: 19.1677\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, text_embed_dim, img_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim + text_embed_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 512), nn.ReLU(),\n",
    "            nn.Linear(512, img_size * img_size * 3), nn.Tanh()\n",
    "        )\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def forward(self, noise, text_embedding):\n",
    "        x = torch.cat((noise, text_embedding), dim=1)\n",
    "        x = self.model(x)\n",
    "        return x.view(-1, 3, self.img_size, self.img_size)\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size, text_embed_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_size * img_size * 3 + text_embed_dim, 512), nn.ReLU(),\n",
    "            nn.Linear(512, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, text_embedding):\n",
    "        img = img.view(img.size(0), -1)\n",
    "        x = torch.cat((img, text_embedding), dim=1)\n",
    "        return self.model(x)\n",
    "\n",
    "# Hyperparameters\n",
    "noise_dim, text_embed_dim, img_size = 100, 128, 64\n",
    "batch_size, lr, num_epochs = 32, 0.0002, 100\n",
    "\n",
    "# Models, Loss, Optimizers\n",
    "G, D = Generator(noise_dim, text_embed_dim, img_size).to(device), Discriminator(img_size, text_embed_dim).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G, optimizer_D = optim.Adam(G.parameters(), lr=lr), optim.Adam(D.parameters(), lr=lr)\n",
    "\n",
    "# Data generation\n",
    "def generate_noise(batch_size, noise_dim):\n",
    "    return torch.randn(batch_size, noise_dim).to(device)\n",
    "\n",
    "def generate_text_embeddings(batch_size, text_embed_dim):\n",
    "    return torch.randn(batch_size, text_embed_dim).to(device)\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for _ in range(batch_size):\n",
    "        real_imgs = torch.randn(batch_size, 3, img_size, img_size).to(device)\n",
    "        real_text = generate_text_embeddings(batch_size, text_embed_dim)\n",
    "        noise = generate_noise(batch_size, noise_dim)\n",
    "        fake_text = generate_text_embeddings(batch_size, text_embed_dim)\n",
    "\n",
    "        # Discriminator\n",
    "        fake_imgs = G(noise, fake_text)\n",
    "        d_loss = criterion(D(real_imgs, real_text), torch.ones(batch_size, 1).to(device)) + \\\n",
    "                 criterion(D(fake_imgs.detach(), fake_text), torch.zeros(batch_size, 1).to(device))\n",
    "        optimizer_D.zero_grad(); d_loss.backward(); optimizer_D.step()\n",
    "\n",
    "        # Generator\n",
    "        g_loss = criterion(D(fake_imgs, fake_text), torch.ones(batch_size, 1).to(device))\n",
    "        optimizer_G.zero_grad(); g_loss.backward(); optimizer_G.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_image(fake_imgs[:25], f'generated_images_{epoch + 1}.png', nrow=5, normalize=True)\n",
    "\n",
    "# Save models\n",
    "torch.save(G.state_dict(), 'generator.pth')\n",
    "torch.save(D.state_dict(), 'discriminator.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8592fd32-6a0f-436a-bc52-e45f539b900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n",
      "Downloading torchvision-0.20.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m471.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6081dc3-b2ed-4fc1-919b-896703c2f9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
